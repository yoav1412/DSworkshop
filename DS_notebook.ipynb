{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_data_files = True  # if set to False, data will be loaded from saved files"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "Load full users and taps datasets from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading taps files: 100/622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading taps files: 200/622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading taps files: 300/622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading taps files: 400/622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading taps files: 500/622\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-3e07b1013acf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mkaggle_users\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mkaggle_taps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_merged_taps_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mkaggle_taps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclean_bad_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkaggle_taps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mkaggle_taps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclean_incompatible_user_ids\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkaggle_taps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkaggle_users\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Google Drive\\University\\Year3\\DSWorkshop\\KaggleDataLoader.py\u001b[0m in \u001b[0;36mcreate_merged_taps_dataframe\u001b[1;34m()\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[0mfile_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mTAPS_FILE_NAMES\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[0mtaps_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mread_taps_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTAPS_ROOT_FOLDER\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtaps_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Google Drive\\University\\Year3\\DSWorkshop\\KaggleDataLoader.py\u001b[0m in \u001b[0;36mread_taps_file\u001b[1;34m(filename, dir_path)\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         df = pd.read_csv(dir_path + filename, delimiter='\\t', header=None, error_bad_lines=False,\n\u001b[1;32m---> 47\u001b[1;33m                          usecols=range(8), low_memory=False)\n\u001b[0m\u001b[0;32m     48\u001b[0m         \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTAPS_COLUMNS\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mEmptyDataError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    708\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 709\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    710\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 455\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    456\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1067\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'skipfooter not supported for iteration'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1069\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1070\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1071\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'as_recarray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1837\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1838\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1839\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1840\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1841\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\pandas\\core\\dtypes\\common.py\u001b[0m in \u001b[0;36mis_integer_dtype\u001b[1;34m(arr_or_dtype)\u001b[0m\n\u001b[0;32m    775\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mis_integer_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m     \"\"\"\n\u001b[0;32m    779\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mprovided\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mof\u001b[0m \u001b[0man\u001b[0m \u001b[0minteger\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "from KaggleDataLoader import *\n",
    "\n",
    "if not process_data_files:\n",
    "    kaggle_taps = pd.read_csv(KAGGLE_TAPS_INPUT)\n",
    "    print(kaggle_taps.head())\n",
    "    kaggle_users = pd.read_csv(KAGGLE_USERS_INPUT)\n",
    "    print(kaggle_users.head())\n",
    "\n",
    "else:\n",
    "    # Create dataframe from files, perform basic cleaning\n",
    "    kaggle_users = create_merged_users_details_file()\n",
    "    print(kaggle_users.head())\n",
    "    \n",
    "    kaggle_taps = create_merged_taps_dataframe()\n",
    "    kaggle_taps = clean_bad_values(kaggle_taps)\n",
    "    kaggle_taps = clean_incompatible_user_ids(kaggle_taps, kaggle_users)\n",
    "    print(kaggle_taps.head())\n",
    "    \n",
    "    \n",
    "    # Filter outliers\n",
    "    def filter_column_by_quantile(df, column, threshold):\n",
    "        len_before = len(df)\n",
    "        df = df[df[column] < np.percentile(df[column], threshold)]\n",
    "        len_after = len(df)\n",
    "        print(\"Filtered out {} rows with outliers in column '{}'\".format((len_before - len_after), column))\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def plot_percentiles_of_column(df, col, start, end, bins):\n",
    "        X = np.linspace(start, end, bins)\n",
    "        Y = [np.percentile(df[col], x) for x in X]\n",
    "        plt.plot(X, Y)\n",
    "        plt.title(col + \" Percentiles\")\n",
    "        plt.xlabel(\"Percent\")\n",
    "        plt.ylabel(\"Percentile Value\")\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    # Filter out outliers of HoldTime:\n",
    "    plot_percentiles_of_column(kaggle_taps, 'HoldTime', 99.96, 99.9999, 20)\n",
    "    # After the percentile 99.993 we see significantly higher values, which are definitely outliers.\n",
    "    kaggle_taps = filter_column_by_quantile(kaggle_taps, 'HoldTime', 99.993)\n",
    "    \n",
    "    # Add parsed date and time column + calculate cumulative time\n",
    "    kaggle_taps = add_cumulative_timestamps_column(kaggle_taps)\n",
    "    \n",
    "    \n",
    "    # Group to bin indexes by the cumulative timestamps\n",
    "    def build_bins(df, bin_size_seconds):\n",
    "        df[\"PressTimeCumulative\"] = df[\"PressTimeCumulative\"] / 1000\n",
    "        max_press = (int(max((df[\"PressTimeCumulative\"])) / bin_size_seconds) + 1) * bin_size_seconds + 1\n",
    "        user_bins = [i for i in range(0, max_press, bin_size_seconds)]\n",
    "        df[\"binIndex\"] = pd.cut((df[\"PressTimeCumulative\"]), user_bins)\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    kaggle_taps = build_bins(kaggle_taps, 90)\n",
    "    \n",
    "    # Keep only necessary columns and save to file\n",
    "    kaggle_taps = kaggle_taps[TAPS_FINAL_COLUMNS + ['binIndex']]\n",
    "    print(kaggle_taps.head())\n",
    "    \n",
    "    kaggle_taps.to_csv(constants.KAGGLE_TAPS_INPUT, index=False)"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "Load full users and taps datasets from MIT dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered out 1 rows with bad values in column 'HoldTime'\nFiltered out 3504 rows with bad values in column 'LatencyTime'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered out 12987 rows with bad values in column 'FlightTime'\nFiltered out 0 rows with bad values in column 'pressTime'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered out 10664 rows with bad values in column 'Hand'\nFiltered out 16481 rows with bad values in column 'Direction'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered out 17 rows with outliers in column 'HoldTime'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered out 966 rows with outliers in column 'LatencyTime'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered out 81 rows with outliers in column 'FlightTime'\n"
     ]
    }
   ],
   "source": [
    "from MITDataLoader import *\n",
    "\n",
    "if not process_data_files:\n",
    "    mit_taps = pd.read_csv(MIT_TAPS_INPUT)\n",
    "    print(mit_taps.head())\n",
    "    mit_users = pd.read_csv(MIT_USERS_INPUT)\n",
    "    print(mit_users.head())\n",
    "\n",
    "else:\n",
    "    mit_users = pd.read_csv(USERS, delimiter=',', header=0, error_bad_lines=False,\n",
    "                            low_memory=False, usecols=[\"pID\", \"gt\", \"updrs108\", \"file_1\", \"file_2\"])\n",
    "    \n",
    "    mit_taps = create_merged_taps_dataframe()\n",
    "    mit_taps = clean_errors_and_bad_values(mit_taps)\n",
    "    \n",
    "    # Group to bin indexes by pressTime and add as a new column\n",
    "    bin_size_seconds = 90\n",
    "    max_press = (int(max(mit_taps[\"pressTime\"]) / bin_size_seconds) + 1) * bin_size_seconds + 1\n",
    "    user_bins = [i for i in range(0, max_press, bin_size_seconds)]\n",
    "    mit_taps[\"binIndex\"] = pd.cut(mit_taps[\"pressTime\"], user_bins)\n",
    "    print(mit_taps.head())\n",
    "    \n",
    "    \n",
    "    # Filter outliers\n",
    "    \n",
    "    def plot_percentile(df, column, start, end, bins):\n",
    "        X = np.linspace(start, end, bins)\n",
    "        Y = [np.percentile(df[column], x) for x in X]\n",
    "        plt.plot(X, Y)\n",
    "        plt.title(column + \" Percentiles\")\n",
    "        plt.xlabel(\"Percent\")\n",
    "        plt.ylabel(\"Percentile Value\")\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    def filter_column_by_quantile(df, column, threshold):\n",
    "        len_before = len(df)\n",
    "        df = df[df[column] < np.percentile(df[column], threshold)]\n",
    "        len_after = len(df)\n",
    "        print(\"Filtered out {} rows with outliers in column '{}'\".format((len_before - len_after), column))\n",
    "    \n",
    "    \n",
    "    if SHOW_PLOTS:\n",
    "        for col in list(set(FLOAT_COLUMNS) - {\"pressTime\"}):\n",
    "            plot_percentile(mit_taps, col, 98, 99.9999, 40)\n",
    "    \n",
    "    # Filter according to the results in the plots\n",
    "    filter_column_by_quantile(mit_taps, \"HoldTime\", 99.99)\n",
    "    filter_column_by_quantile(mit_taps, \"LatencyTime\", 99.4)\n",
    "    filter_column_by_quantile(mit_taps, \"FlightTime\", 99.95)\n",
    "    \n",
    "    # Save to file - Taps file\n",
    "    mit_taps[[\"HoldTime\", \"LatencyTime\", \"FlightTime\"]] = \\\n",
    "        1000 * mit_taps[[\"HoldTime\", \"LatencyTime\", \"FlightTime\"]]  # to milliseconds\n",
    "    print(mit_taps.head())\n",
    "    \n",
    "    mit_taps.to_csv(MIT_TAPS_INPUT, index=False)\n",
    "    \n",
    "    # Save to file - Users file\n",
    "    mit_users.rename(columns={'pID': 'ID', 'gt': 'Parkinsons', 'updrs108': 'UDPRS'}, inplace=True)\n",
    "    mit_users = mit_users[['ID', 'Parkinsons', 'UDPRS']]\n",
    "    print(mit_users.head())\n",
    "    \n",
    "    mit_users.to_csv(MIT_USERS_INPUT, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
